{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1>Stream on GPU</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vector Add\n",
    "\n",
    "In the world of computing, the addition of two vectors is the standard \"Hello World\". \n",
    "\n",
    "![vector add](./images/vector_add.png \"Vector Addition\")\n",
    "\n",
    "Given two sets of scalar data, such as the image above, we want to compute the sum, element by element. \n",
    "\n",
    "We start by implementing the algorithm in plain C#. \n",
    "\n",
    "Edit the file [01-naive-add.cs](../../edit/03_Streams/01-naive-add/01-naive-add.cs) and implement this algorithm in plain C# until it displays `OK`\n",
    "\n",
    "If you get stuck, you can refer to the [solution](../../edit/03_Streams/01-naive-add/solution/01-naive-add.cs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hybridizer-cuda ./01-naive-add/01-naive-add.cs -o ./01-naive-add/naive-add.exe -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## With Parallelism\n",
    "\n",
    "As we can see in the [solution](../../edit/03_Streams/01-naive-add/solutions/01-naive-add.cs), a plain scalar iterative approach only uses one thread, while modern CPUs have typically 4 cores and 8 threads. \n",
    "\n",
    "Fortunately, .Net and C# provide an intuitive construct to leverage parallelism : [Parallel.For](https://msdn.microsoft.com/en-us/library/dd783539.aspx). \n",
    "\n",
    "Modify [01-naive-add.cs](../../edit/03_Streams/01-naive-add/01-naive-add.cs) to distribute the work among multiple threads. \n",
    "\n",
    "If you get stuck, you can refer to the [solution](../../edit/03_Streams/01-naive-add/solution/02-parallel-add.cs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hybridizer-cuda ./01-naive-add/01-naive-add.cs -o ./01-naive-add/parallel-add.exe -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Code on the GPU\n",
    "\n",
    "Using Hybridizer to run the above code on a GPU is quite straightforward. We need to\n",
    "- Decorate methods we want to run on the GPU  \n",
    "This is done by adding `[EntryPoint]` attribute on methods of interest. \n",
    "- \"Wrap\" current object into a dynamic object able to dispatch code on the GPU\n",
    "This is done by the following boilerplate code:  \n",
    "```csharp\n",
    "dynamic wrapped = HybRunner.Cuda().Wrap(new Program());\n",
    "wrapped.mymethod(...);\n",
    "```\n",
    "`wrapped` object has the same methods signatures (static or instance) as the current object, but dispatches calls to GPU.\n",
    "\n",
    "Modify the [02-gpu-add.cs](../../edit/03_Streams/02-gpu-add/02-gpu-add.cs) so the `Add` method runs on a GPU. \n",
    "\n",
    "If you get stuck, you can refer to the [solution](../../edit/03_Streams/02-gpu-add/solution/02-gpu-add.cs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hybridizer-cuda ./02-gpu-add/02-gpu-add.cs -o ./02-gpu-add/gpu-add.exe -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Manage Memory\n",
    "\n",
    "Now you can manage your memory yourself. Even if you want to have your data on the device. With the hybridizer all is implemented to let you choose where you want to stock your data.\n",
    "\n",
    "For that we need to :\n",
    "- Allow the use of unsafe code\n",
    "- Create an `IntPtr` for the device and allocate it with\n",
    "```csharp\n",
    "IntPtr d_a;\n",
    "//N is the size of the array you want to allocate \n",
    "cuda.Malloc(out d_a, N * sizeof(datatype));\n",
    "```\n",
    "- Use `GCHandle` to pin a c# array ([Alloc](https://msdn.microsoft.com/en-us/library/1246yz8f.aspx) & [AddrOfPinnedObject](https://msdn.microsoft.com/en-us/library/system.runtime.interopservices.gchandle.addrofpinnedobject.aspx)): \n",
    "```csharp\n",
    "float[] a = new float[N];\n",
    "GCHandle handle_a = GCHandle.Alloc(a, GCHandleType.Pinned);\n",
    "IntPtr h_a = handle_a.AddrOfPinnedObject();\n",
    "```\n",
    "- Copy the data on the device with your device pointer and your pinned c# pointer\n",
    "```csharp\n",
    "cuda.Memcpy(d_a,\n",
    "            h_a,\n",
    "            N * sizeof(float),\n",
    "            cudaMemcpyKind.cudaMemcpyHostToDevice);\n",
    "```\n",
    "\n",
    "- After you launch the kernel you can return the device data on the host\n",
    "```csharp\n",
    "cuda.Memcpy(h_a,\n",
    "             d_a,\n",
    "             N * sizeof(float),\n",
    "             cudaMemcpyKind.cudaMemcpyDeviceToHost);\n",
    "```\n",
    "- Make sure before each copy between the host and the device, the device is synchronize.\n",
    "\n",
    "- Don't forget to free the memory of your GChandle ([free](https://msdn.microsoft.com/en-us/library/system.runtime.interopservices.gchandle.free.aspx))\n",
    "```csharp\n",
    "handle_a.Free();\n",
    "```\n",
    "\n",
    "Modify the [03-malloc-add.cs](../../edit/03_Streams/03-malloc-add/03-malloc-add.cs) so you allocate and use some device pointer. \n",
    "\n",
    "If you get stuck, you can refer to the [solution](../../edit/03_Streams/03-malloc-add/solution/03-malloc-add.cs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hybridizer-cuda ./03-malloc-add/03-malloc-add.cs -o ./03-malloc-add/maloc-add.exe -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STREAM\n",
    "\n",
    "the purpose of this example is to allow you to use streams with the Hybridizer, on one very big vector without cut it. We will use 8 streams for this example.\n",
    "\n",
    "- You can create a stream with the object `cudaStream_t` and  `cuda.StreamCreate(out yourStream)`.\n",
    "- To set a stream on a kernel you have to use the `SetStream(stream)` function on `wrapped`.\n",
    "```csharp\n",
    "wrapped.SetStream(stream).mymethod(...);\n",
    "```\n",
    "- You have the possibility to make an asynchronous cudaMemCpy when you copy data\n",
    "```csharp\n",
    "cuda.MemcpyAsync(IntPtr dst, IntPtr src, size_t size, cudaMemcpyKind kindOfCopy, cudaStream_t stream =0);\n",
    "```\n",
    "- You can block until the stream finish to compute with `cuda.StreamSynchronize(stream)`.\n",
    "- Finally destroy your stream with `cuda.StreamDestroy(stream)`.\n",
    "\n",
    "Modify the [04-stream-add.cs](../../edit/03_Streams/04-stream-add/04-stream-add.cs) so you can create and use multiple streams.\n",
    "\n",
    "If you get stuck, you can refer to the [solution](../../edit/03_Streams/04-stream-add/solution/04-stream-add.cs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hybridizer-cuda ./04-stream-add/04-stream-add.cs -o ./04-stream-add/stream-add.exe -run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
